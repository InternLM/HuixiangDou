["这种，看着就大佬味道",
"[吃瓜]本垃圾有预算保养一位懂驱动 懂内核的大佬。",
"大佬困扰好几天了",
"有大佬用onnx 的fp 16模型转TNN嘛",
"「巅峰、少成: 大佬们。麻烦咨询下，mmdeploy推理的时候怎么限制内存呢？限制遇到连续几次就会出现Insufficient memory」\n—————————\nbackend 用的啥，按我理解，大多数是不能的",
"大佬们 有人知道yolo的txt格式数据的深度挖掘怎么做吗",
"想问下大佬们，rtmpose预测的关检点得分为什么会是大于1的呢，这个得分的范围是怎样的呢",
"打扰大佬，还有一个mmpose的问题，我使用单人的视频，输出的json文件，好多frame里面有两组 key_points, box_score 都是 1，但是第一组的keypoint_score 比第二组高。为啥会输出两组呢？",
"感谢各位大佬 上个问题解决了[Salute] 有一个新问题 我用“wholebody”测一个没有人出现的片段[捂脸]，保存的json当中几乎所有的bbox_score得分都是1 ，这个1是什么意思呀？",
"悟了 感谢大佬",
"想请教群里各位大佬。为啥ViT的权重初始化这么复杂呀？分类头linear、mlp的linear、其他linear的初始化方式都不一样",
"好的，谢谢大佬们",
"各位大佬们  有谁知道用mmdeploy_runtime 跑cuda版本的onnx模型(mmdeploy转出的onnx模型)时报错：libonnxruntime_providers_shared.so: cannot open shared object file: No such file or directory 是怎么一回事吗",
"nuscenes数据集在火山云上，本地如何读取他的pkl文件，有大佬能指点一二吗？",
"让大佬开个奇妙夜",
"感谢大佬答疑解惑～",
"大佬们，下载了git，但是在anaconda的命令窗口安装mmpose还是显示显示‘git’不是内部或外部命令，也不是可运行的程序或批处理文件。这怎么弄？",
"我现在想混个研究生文凭 大佬们有没有什么建议？",
"你好，这是我测试的Yi-34B-base的tydiqa的值，跟leaderboard的值对应不上，麻烦大佬看一下",
"所以大佬有空的话实现一下呗[苦涩]，我真的很难顶",
"大佬们新年好！topdown的方法中，我想一次读取9张图片进行预测，但是目前的设备不支持批处理。想着将读取的数据进行拼接后送入网络，经过backbone，head分成九路输出。但是对于数据读取（或者前处理）这块不知道该如何处理。有大佬能指教嘛？能否通过写一个data transform的类将前处理后的batch数据进行拼接？然后再送入网络呢",
"各位大佬，我想了解一下metain元文件中的joint_weights与sigmas参数的大小是怎么定义设置的？是不是joint_weights越大，模型越专注训练这个点，sigmas越大是不是表示在这个点越难学？",
"大佬又开始送东西",
"需要每一个大佬的PR和star",
"大佬们 新年快乐！",
"求我大佬们，立体匹配有类似mmlab和detectron这样的代码库吗，找了好像没找到",
"大佬们 问一个问题 我用mmdeploy的trt模型进行推理（检测模型），同一张图片，推多次结果总是有细微的差距，求大佬解答，这个正常吗？ ",
"我这看了好多资料了[流泪]，大佬快教",
"来自语音圈大佬的评价[嘿哈]",
"各位大佬们 mmseg用--resume接着训练卡住了咋办呀[捂脸]",
"有没有大佬安装mmcv遇到中这个情况，我安装csdn操作之后cuda版本好像变成9 了",
"大佬，h800能不能给我们访问下",
"[捂脸][捂脸]大佬好",
"佬，slam 大佬有兴趣给面试报价吗？",
"这个问题是在寻求某方面的帮助，并且表示对对方的敬意和友好态度。其中，“哪位大佬有经验”是询问是否有熟悉相关领域的人能够提供指导，“帮忙指导下”则是希望对方能够给予具体的帮助和建议。而“[抱拳][笑脸]”则是一种表情符号，用来表达礼貌和友好的情绪。",
"请教一下群里的各位大佬  MMDeploy Android的框架能否使用NPU  支持rk3588这种处理器上运行吗？",
"有文档吗？大佬",
"大佬们，我有个疑问。已知大模型和agent的智力暂时还是有限的，原因是没法做错误的推理判断和辨别；所以我们让大模型 agent做智力范围内的事情是很好的。那我们有没有一种判别法，可以让判断出大模型/某个agent在某件事情上的靠谱程度，来决定是否可以让它扮演那个角色？ 有什么方法可以判断他是靠谱还是不靠谱的（非概率） 目前这个只能靠人类",
"各位大佬请教，要是使用mmpose训练自己的数据集需要标注的时候，有什么推荐的标注工具吗？",
"请问哪位大佬有deep image matting数据集，求分享[抱拳]",
"大佬师平时在家过年跑路也很让人羡慕",
"请问一下大佬，我在用mmdeploy导出rtmdet的onnx模型后，在检测的时候有三个目标，但输出了四个，并且最后一个目标全为0，这种情况怎么解决呢？",
"大佬，训练200epoch的rtmpose，感觉他们变化很小，变化很慢啊，120epoch了loss_kpt:才0.944左右，acc_pose也是一直在0.896左右，这训练正不正常阿？",
"大佬们，我不懂mmdeploy是怎么做的，是否可以认为支持的模型部署是大于支持的模型转换的呢，否则应该能转换就能部署哇？",
"有大佬用过mmaction2嘛",
"大佬们。麻烦咨询下，mmdeploy推理的时候怎么限制内存呢？限制遇到连续几次就会出现Insufficient memory",
"各位大佬请教一下，如果想买intel的design tool kit，该怎么搞intel的开发者账号",
"好滴谢谢大佬  可以直接说它等于 fps 吗  还是有什么计算，我看前面有个 10 runs",
"各位大佬用的什么",
"大佬，mmpose返回值tuple，但是我想在后面继续加操作要怎么搞",
"大佬一个hrnet训练出来，一个epoch占七百多内存，正常吗",
"换个群，已经拿了几个”感谢大佬”了。",
"大佬们，请问如何mm让茴香豆mm回答问题mm",
"那大佬可以把闲置的qqc租出去",
"呜呜呜 小白 求大佬说详细点 愿意学  愿意改",
"https://spaces.ac.cn/ 这个大佬写过一些，可以瞅瞅",
"各位大佬，我想咨询一个模型训练的问题。我有一组Ms coco格式的关键点数据集，里面标注了66个关键点，但我只想用其中的30个关键点来训练模型，并且不考虑点之间的连接关系。这种情况能实现吗，如何修改配置文件",
"可恶，群里这么多大佬发CVPR，我只能乖乖当个分母了",
"有大佬推荐一个比较好跑的backbone模型吗",
"请问大佬们有在工程部署中，有多个pytorch模型使用多线程来同时推理？",
"大佬们，这什么情况",
"大佬，训练rtmpose时batch大于100就会出现这个错误怎么回事啊？明明显卡内存还有足够的量使用",
"有大佬用过onnx的静态int8量化嘛",
"有没有大佬知道",
"大佬们mmdete3d可以生成PR曲线吗",
"大佬们可以帮忙看看这个数据配置文件吗",
"大佬们，我跑yolov8 关键点检测报这种错",
"看了大佬发的这个，感觉前途黯淡",
"大佬在ICCAD展咩",
"有大佬知道这个报错是什么原因么",
"大佬知道什么是 小黑子、鸡你太美 吗？",
"有大佬有百度和腾讯的lab内推吗，感谢",
"不过大佬单子盈利能力强 确实不在乎",
"有没有大佬能发一个正常deploy 的chenk_env输出看下呢。。",
"我很好奇，大佬做这个怎么写论文呢？是什么指标提升上去了，就可以写论文了吗",
"有大佬知道这是什么原因吗 mmseg",
"有大佬知道这个问题嘛，运行lmdeploy chat turbomind就会出现\nYou\n<|System|>:You are an AI assistant whose name is InternLM (书生·浦语). - InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless. - InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文. <|User|>:what the fucking doing! <|Bot|>: [AMP ERROR][CudaFrontend.cpp:94][1705464911:579595]failed to call cuCtxGetDevice(&device), error code: CUDA_ERROR_INVALID_CONTEXT =============================================== Back trace dump: /usr/local/harp/lib/libvirtdev-frontend.so.0(LogStream::PrintBacktrace()+0x52) [0x7fbcea3f2302] /lib/x86_64-linux-gnu/libcuda.so.1(CudaFeApiStateData::GetCurrentDevicePciBusId(Frontend*, int const*)+0x241) [0x7fbcea621471] /lib/x86_64-linux-gnu/libcuda.so.1(python: CudaFrontend.cpp:94: static const string& CudaFeApiStateData::GetCurrentDevicePciBusId(Frontend*, const CUdevice*): Assertion `0' failed. Aborted (core dumped) \n",
"嘿嘿嘿，听说 猫腻 被大佬拐进来了",
"请教大佬一个问题，mmaction2的demo_skeleton生成的视频为啥打不开",
"大佬，我看rtmo可以加aic这种数据集训练，但我印象中aic不是没标全部的人体框么，一阶段能加这种数据训？",
"有大佬熟悉ptx指令的吗？lmdeploy里面有个把共享内存拷贝到全局内存的ptx指令，怎么在不使用ptx指令的情况下，实现该功能。template<typename T>\n__inline__ __device__ void cp_async_ca(uint32_t smem_int_ptr, const T* __restrict__ src, bool mask)\n{\n#if TURBOMIND_ARCH_SM80\n    constexpr int cp_size = sizeof(T);\n    // clang-format off\n    asm volatile(\"{\\n\"\n                 \"  .reg .pred p;\\n\"\n                 \"  setp.ne.b32 p, %0, 0;\\n\"\n                 \"  @p cp.async.ca.shared.global\" L2_CACHEHINT(128) \" [%1], [%2], %3;\\n\"\n                 \"}\\n\" ::\"r\"((int)mask),\n                 \"r\"(smem_int_ptr),\n                 \"l\"(src),\n                 \"n\"(cp_size));\n    // clang-format on\n#else\n    assert(TURBOMIND_ARCH_SM80);\n#endif\n}",
"求助大佬们，我尝试跑msagent数据集失败了[流泪]\nhttps://github.com/InternLM/xtuner/issues/205",
"那算了[捂脸]谢谢大佬",
"想请教下大佬，",
"Better models of human high-level visual cortex emerge from natural language supervision with a large and diverse dataset\n有大佬， 可以帮忙下载一下这篇nature论文吗[可怜][可怜][可怜][可怜]",
"大佬居然不知道？"
]
