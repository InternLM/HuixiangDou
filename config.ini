[feature_store]
# `feature_store.py` use this throttle to distinct `good_questions` and `bad_questions`
reject_throttle = -1.0
# text2vec model, support local relative path, huggingface repo and URL.
# for example:
#  "maidalun1020/bce-embedding-base_v1"
#  "BAAI/bge-m3"
#  "https://api.siliconflow.cn/v1/embeddings"
embedding_model_path = "maidalun1020/bce-embedding-base_v1"

# reranker model, support list:
#  "maidalun1020/bce-reranker-base_v1"
#  "BAAI/bge-reranker-v2-minicpm-layerwise"
#  "https://api.siliconflow.cn/v1/rerank"
reranker_model_path = "maidalun1020/bce-reranker-base_v1"

# if using `siliconcloud` API as `embedding_model_path` or `reranker_model_path`, give the token
api_token = ""
api_rpm = 1000
work_dir = "workdir"

[web_search]
engine = "serper"
serper_x_api_key = ""
domain_partial_order = ["openai.com", "pytorch.org", "readthedocs.io", "nvidia.com", "stackoverflow.com", "juejin.cn", "zhuanlan.zhihu.com", "www.cnblogs.com"]
save_dir = "logs/web_search_result"

[llm]
enable_local = 1
enable_remote = 0
client_url = "http://127.0.0.1:8888/inference"
client_stream_url = "http://127.0.0.1:8888/stream"

[llm.server]
local_llm_path = "/data2/khj/internlm2_5-7b-chat/"
local_llm_max_text_length = 3000
local_llm_bind_port = 8888
remote_type = "siliconcloud"
remote_api_key = ""
remote_llm_max_text_length = 40000
remote_llm_model = "alibaba/Qwen1.5-110B-Chat"
rpm = 1000

[coreference_resolution]
base_url = "http://127.0.0.1:9999/v1"
api_key = "token-abc123"

[worker]
enable_web_search = 1
enable_sg_search = 1
enable_cr = 0
save_path = "logs/generate.jsonl"

[worker.time]
enable = 0
start = "00:00:00"
end = "23:59:59"
has_weekday = 1

[sg_search]
binary_src_path = "/usr/local/bin/src"
src_access_token = "sgp_636f79ad2075640f_3ef2a135579615403e29b88d4402f1e6183ad347"

[sg_search.opencompass]
github_repo_id = "open-compass/opencompass"
introduction = "用于评测大型语言模型（LLM）. 它提供了完整的开源可复现的评测框架，支持大语言模型、多模态模型的一站式评测，基于分布式技术，对大参数量模型亦能实现高效评测。评测方向汇总为知识、语言、理解、推理、考试五大能力维度，整合集纳了超过70个评测数据集，合计提供了超过40万个模型评测问题，并提供长文本、安全、代码3类大模型特色技术能力评测。"

[sg_search.lmdeploy]
github_repo_id = "internlm/lmdeploy"
introduction = "lmdeploy 是一个用于压缩、部署和服务 LLM（Large Language Model）的工具包。是一个服务端场景下，transformer 结构 LLM 部署工具，支持 GPU 服务端部署，速度有保障，支持 Tensor Parallel，多并发优化，功能全面，包括模型转换、缓存历史会话的 cache feature 等. 它还提供了 WebUI、命令行和 gRPC 客户端接入。"

[sg_search.mmpose]
github_repo_id = "open-mmlab/mmpose"
introduction = "MMPose is an open-source toolbox for pose estimation based on PyTorch"

[sg_search.mmdetection]
github_repo_id = "open-mmlab/mmdetection"
introduction = "MMDetection is an open source object detection toolbox based on PyTorch."

[sg_search.huixiangdou]
github_repo_id = "internlm/huixiangdou"
introduction = "茴香豆是一个基于 LLM 的群聊知识助手。设计拒答、响应两阶段 pipeline 应对群聊场景，解答问题同时不会消息泛滥。"

[sg_search.xtuner]
github_repo_id = "internlm/xtuner"
introduction = "XTuner is an efficient, flexible and full-featured toolkit for fine-tuning large models."

[sg_search.mmyolo]
github_repo_id = "open-mmlab/mmyolo"
introduction = "OpenMMLab YOLO series toolbox and benchmark. Implemented RTMDet, RTMDet-Rotated,YOLOv5, YOLOv6, YOLOv7, YOLOv8,YOLOX, PPYOLOE, etc."

[sg_search.Amphion]
github_repo_id = "open-mmlab/Amphion"
introduction = "Amphion is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development."

[sg_search.mmcv]
github_repo_id = "open-mmlab/mmcv"
introduction = "MMCV is a foundational library for computer vision research and it provides image/video processing, image and annotation visualization, image transformation, various CNN architectures and high-quality implementation of common CPU and CUDA ops"

[frontend]
type = "none"
webhook_url = "https://open.feishu.cn/open-apis/bot/v2/hook/xxxxxxxxxxxxxxx"
message_process_policy = "immediate"

[frontend.lark_group]
app_id = "cli_a53a34dcb778500e"
app_secret = "2ajhg1ixSvlNm1bJkH4tJhPfTCsGGHT1"
encrypt_key = "abc"
verification_token = "def"

[frontend.wechat_personal]
bind_port = 9527

[frontend.wechat_wkteam]
account = "18612393510"
password = "5g!XmZ4C"
proxy = 3
dir = "wkteam"
callback_ip = "101.133.161.204"
callback_port = 9528
redis_host = "101.133.161.204"
redis_port = "6380"
redis_passwd = "hxd123"

[frontend.wechat_wkteam.44546611710]
name = "茴香豆群（立夏）"
introduction = "github https://github.com/InternLM/HuixiangDou 用户体验群"

[frontend.wechat_wkteam.38720590618]
name = "茴香豆群（惊蛰）"
introduction = "github https://github.com/InternLM/HuixiangDou 用户体验群"

[frontend.wechat_wkteam.48437885473]
name = "茴香豆群（谷雨）"
introduction = "github https://github.com/InternLM/HuixiangDou 用户体验群"

[frontend.wechat_wkteam.34744063953]
name = "茴香豆群（雨水）"
introduction = "github https://github.com/InternLM/HuixiangDou 用户体验群"

[frontend.wechat_wkteam.20158567857]
name = "开发测试群（企微）"
introduction = ""

[frontend.wechat_wkteam.21375247392]
name = "开发测试群（个微）"
introduction = ""

[frontend.wechat_wkteam.22929032366]
name = "OpenMMLab 群"
introduction = "Open喵喵Lab"

[frontend.wechat_wkteam.20814553575]
name = "mmhuman3d 和 mmpose 社区2群"
introduction = "mmpose 用户群"

[frontend.wechat_wkteam.21295744750]
name = "openmmlab 贡献者交流群"
introduction = "openmmlab repo contributors"

[frontend.wechat_wkteam.21177113665]
name = "mmdeploy & lmdeploy 社区"
introduction = "模型部署用户群"

[frontend.wechat_wkteam.20933744776]
name = "mmdeploy & lmdeploy 社区 2 群"
introduction = "模型部署用户群"

[frontend.wechat_wkteam.18356748488]
name = "卷卷群"
introduction = "ncnn contributors group"
