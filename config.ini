[feature_store]
reject_throttle = 767.0
# text2vec model path, support local relative path and huggingface model format
model_path = "shibing624/text2vec-base-chinese"
work_dir = "workdir"

[web_search]
# check https://serper.dev/api-key to get a free API key
x_api_key = "${YOUR-API-KEY}"
domain_partial_order = ["openai.com", "pytorch.org", "readthedocs.io", "nvidia.com", "stackoverflow.com", "juejin.cn", "zhuanlan.zhihu.com", "www.cnblogs.com"]
save_dir = "logs/web_search_result"

[llm]
enable_local = 1
enable_remote = 0
# hybrid llm service address
client_url = "http://127.0.0.1:8888/inference"

[llm.server]
# local LLM configuration
# support "internlm2-7B", "internlm2-20B" and "internlm2-70B"
local_llm_path = "/internlm/ampere_7b_v1_7_0"
local_llm_max_text_length = 16000

# remote LLM service configuration
# support any python3 openai interface, such as "gpt", "kimi" and so on
remote_type = "kimi"
remote_api_key = "${YOUR-API-KEY}"
# max text length for remote LLM. for example, use 128000 for kimi, 192000 for gpt
remote_llm_max_text_length = 128000
# openai model type. use "moonshot-v1-128k" for kimi, "gpt-4" for gpt
remote_llm_model = "moonshot-v1-128k"
bind_port = 8888

[worker]
enable_sg_search = 0
save_path = "logs/work.txt"

[worker.time]
start = "00:00:00"
end = "23:59:59"
has_weekday = 1

[sg_search]
binary_src_path = "/usr/local/bin/src"
src_access_token = "${YOUR-SRC-ACCESS-TOKEN}"

# add your repo here, we just take opencompass and lmdeploy as example
[sg_search.opencompass]
github_repo_id = "open-compass/opencompass"
introduction = "用于评测大型语言模型（LLM）. 它提供了完整的开源可复现的评测框架，支持大语言模型、多模态模型的一站式评测，基于分布式技术，对大参数量模型亦能实现高效评测。评测方向汇总为知识、语言、理解、推理、考试五大能力维度，整合集纳了超过70个评测数据集，合计提供了超过40万个模型评测问题，并提供长文本、安全、代码3类大模型特色技术能力评测。"

[sg_search.lmdeploy]
github_repo_id = "internlm/lmdeploy"
introduction = "lmdeploy 是一个用于压缩、部署和服务 LLM（Large Language Model）的工具包。是一个服务端场景下，transformer 结构 LLM 部署工具，支持 GPU 服务端部署，速度有保障，支持 Tensor Parallel，多并发优化，功能全面，包括模型转换、缓存历史会话的 cache feature 等. 它还提供了 WebUI、命令行和 gRPC 客户端接入。"

[frontend]
# chat group type, support "lark" and "none"
# check https://open.feishu.cn/document/client-docs/bot-v3/add-custom-bot to add lark bot
type = "none"
# char group webhook url, send reply to group
webhook_url = "https://open.feishu.cn/open-apis/bot/v2/hook/7a5d3d98-fdfd-40f8-b8de-851cb7e81e5c"