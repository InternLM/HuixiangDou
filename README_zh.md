[English](README.md) | ç®€ä½“ä¸­æ–‡

<div align="center">

<img src="resource/logo_black.svg" width="500px"/>

<div align="center">
  <a href="resource/figures/wechat.jpg" target="_blank">
    <img alt="Wechat" src="https://img.shields.io/badge/wechat-assistant%20inside-brightgreen?logo=wechat&logoColor=white" />
  </a>
  <a href="https://arxiv.org/abs/2401.08772" target="_blank">
    <img alt="Arxiv" src="https://img.shields.io/badge/arxiv-paper%20-darkred?logo=arxiv&logoColor=white" />
  </a>
  <a href="https://pypi.org/project/huixiangdou/" target="_blank">
    <img alt="PyPI" src="https://img.shields.io/badge/PyPI-install-blue?logo=pypi&logoColor=white" />
  </a>
  <a href="https://youtu.be/ylXrT-Tei-Y" target="_blank">
    <img alt="YouTube" src="https://img.shields.io/badge/YouTube-black?logo=youtube&logoColor=red" />
  </a>
  <a href="https://www.bilibili.com/video/BV1S2421N7mn" target="_blank">
    <img alt="BiliBili" src="https://img.shields.io/badge/BiliBili-pink?logo=bilibili&logoColor=white" />
  </a>
</div>

</div>

â€œèŒ´é¦™è±†â€æ˜¯ä¸€ä¸ªåŸºäº LLM çš„é¢†åŸŸçŸ¥è¯†åŠ©æ‰‹ã€‚ç‰¹ç‚¹ï¼š

1. åº”å¯¹ç¾¤èŠè¿™ç±»å¤æ‚åœºæ™¯ï¼Œè§£ç­”ç”¨æˆ·é—®é¢˜çš„åŒæ—¶ï¼Œä¸ä¼šæ¶ˆæ¯æ³›æ»¥
2. æå‡ºä¸€å¥—è§£ç­”æŠ€æœ¯é—®é¢˜çš„ç®—æ³• pipeline
3. éƒ¨ç½²æˆæœ¬ä½ï¼Œåªéœ€è¦ LLM æ¨¡å‹æ»¡è¶³ 4 ä¸ª trait å³å¯è§£ç­”å¤§éƒ¨åˆ†ç”¨æˆ·é—®é¢˜ï¼Œè§[æŠ€æœ¯æŠ¥å‘Š arxiv2401.08772](https://arxiv.org/abs/2401.08772)

æŸ¥çœ‹[èŒ´é¦™è±†å·²è¿è¡Œåœ¨å“ªäº›åœºæ™¯](./huixiangdou-inside.md)ï¼›åŠ å…¥[å¾®ä¿¡ç¾¤](resource/figures/wechat.jpg)ç›´æ¥ä½“éªŒç¾¤èŠåŠ©æ‰‹æ•ˆæœã€‚

å¦‚æœå¯¹ä½ æœ‰ç”¨ï¼Œéº»çƒ¦ star ä¸€ä¸‹â­

# ğŸ”† æ–°åŠŸèƒ½

èŒ´é¦™è±† Web ç‰ˆå·²å‘å¸ƒåˆ° [OpenXLab](https://openxlab.org.cn/apps/detail/tpoisonooo/huixiangdou-web)ï¼Œå¯ä»¥åˆ›å»ºè‡ªå·±çš„çŸ¥è¯†åº“ã€æ›´æ–°æ­£åä¾‹ã€å¼€å…³ç½‘ç»œæœç´¢ï¼ŒèŠå¤©æµ‹è¯•æ•ˆæœåï¼Œé›†æˆåˆ°é£ä¹¦/å¾®ä¿¡ç¾¤ã€‚

Web ç‰ˆè§†é¢‘æ•™ç¨‹è§ [BiliBili](https://www.bilibili.com/video/BV1S2421N7mn) å’Œ [YouTube](https://www.youtube.com/watch?v=ylXrT-Tei-Y)ã€‚

- \[2024/03\] æ”¯æŒ `ppt` å’Œ `html` æ ¼å¼
- \[2024/03\] ä¼˜åŒ– `pdf` å’Œè¡¨æ ¼è§£æï¼Œæ”¹å–„ç²¾åº¦å¹¶åŠ é€Ÿ
- \[2024/03\] æ”¯æŒ [zhipuai](https://zhipuai.cn) å’Œ [xi-api å›½å†… gpt ä»£ç†](https://api.xi-ai.cn)ï¼Œè§ `config.ini`
- \[2024/03\] æ–°çš„[ä¸ªäººå¾®ä¿¡é›†æˆæ–¹æ³•](./docs/add_wechat_accessibility_zh.md)å’Œ[**é¢„ç¼–è¯‘ apk**](https://github.com/InternLM/HuixiangDou/releases/download/v0.1.0rc1/huixiangdou-1.0.0.apk) !
- \[2024/03\] æ”¯æŒ `pdf`/`word`/`excel`ï¼Œè¿”å›å¼•ç”¨çš„æ–‡ä»¶åæˆ– Web URL
- \[2024/02\] ç”¨ [BCEmbedding](https://github.com/netease-youdao/BCEmbedding) rerank æå‡æ£€ç´¢ç²¾åº¦ ğŸ‘
- \[2024/02\] [æ”¯æŒ deepseek](https://github.com/InternLM/HuixiangDou/blob/main/README_zh.md#step2-%E8%BF%90%E8%A1%8C%E5%9F%BA%E7%A1%80%E7%89%88%E6%8A%80%E6%9C%AF%E5%8A%A9%E6%89%8B) å’Œ qwen1.5; æŒ‰ GPU æ˜¾å­˜åŠ¨æ€é€‰æ¨¡å‹
- \[2024/02\] \[å®éªŒåŠŸèƒ½\] [å¾®ä¿¡ç¾¤](https://github.com/InternLM/HuixiangDou/blob/main/resource/figures/wechat.jpg) é›†æˆå¤šæ¨¡æ€ä»¥å®ç° OCR
- \[2024/01\] å®ç°[ä¸ªäººå¾®ä¿¡æ¥å…¥](./docs/add_wechat_group_zh.md); [é£ä¹¦ç¾¤æ”¶å‘å’Œæ’¤å›](./docs/add_lark_group_zh.md)

# ğŸ“¦ ç¡¬ä»¶è¦æ±‚

ä»¥ä¸‹æ˜¯è¿è¡ŒèŒ´é¦™è±†çš„ç¡¬ä»¶éœ€æ±‚ã€‚å»ºè®®éµå¾ªéƒ¨ç½²æµç¨‹ï¼Œä»åŸºç¡€ç‰ˆå¼€å§‹ï¼Œé€æ¸ä½“éªŒé«˜çº§ç‰¹æ€§ã€‚

|  ç‰ˆæœ¬  | GPUæ˜¾å­˜éœ€æ±‚ |                                                                                          æè¿°                                                                                          |                             Linux ç³»ç»Ÿå·²éªŒè¯è®¾å¤‡                              |
| :----: | :---------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------------: |
| ä½“éªŒç‰ˆ |    1.5GB    | ç”¨ [openai API](https://pypi.org/project/openai/)ï¼ˆå¦‚ [kimi](https://kimi.moonshot.cn) å’Œ [deepseek](https://platform.deepseek.com/usage)ï¼‰æ›¿ä»£æœ¬åœ° LLMï¼Œå¤„ç†æºç çº§é—®é¢˜ã€‚<br/>é™é¢å…è´¹ | ![](https://img.shields.io/badge/1660ti%206G-passed-blue?style=for-the-badge) |
| åŸºç¡€ç‰ˆ |    19GB     |                                                                         æœ¬åœ°éƒ¨ç½² LLMï¼Œèƒ½å›ç­”é¢†åŸŸçŸ¥è¯†çš„åŸºç¡€é—®é¢˜                                                                         | ![](https://img.shields.io/badge/3090%2024G-passed-blue?style=for-the-badge)  |
| é«˜çº§ç‰ˆ |    40GB     |                                                                      å……åˆ†åˆ©ç”¨æ£€ç´¢+é•¿æ–‡æœ¬èƒ½åŠ›ï¼Œèƒ½å¤Ÿå›ç­”æºç çº§é—®é¢˜                                                                       | ![](https://img.shields.io/badge/A100%2080G-passed-blue?style=for-the-badge)  |

å¦‚æœä½ åªæœ‰ 2G æ˜¾å­˜ï¼Œæˆ–è¿½æ±‚æ€§ä»·æ¯”ğŸ’°ï¼Œ[çœ‹è¿™ä¸ªçŸ¥ä¹æ–‡æ¡£](https://zhuanlan.zhihu.com/p/685205206)ã€‚

# ğŸ”¥ è¿è¡Œ

æˆ‘ä»¬å°†ä»¥ mmpose å’Œä¸€äº› `word`/`excel`/`pdf`/`ppt` æµ‹è¯•æ–‡æ¡£ä¸ºä¾‹ï¼Œä»‹ç»å¦‚ä½•æŠŠçŸ¥è¯†åŠ©æ‰‹éƒ¨ç½²åˆ°é£ä¹¦ç¾¤

## STEP1. å»ºç«‹è¯é¢˜ç‰¹å¾åº“

ç”±äº [embedding](https://huggingface.co/maidalun1020/bce-embedding-base_v1) å’Œ [rerank](https://huggingface.co/maidalun1020/bce-reranker-base_v1) æ¨¡å‹éœ€è¦éªŒè¯æ‰èƒ½è·å–ï¼Œä½ éœ€è¦ç™»å½• huggingfaceã€‚ä¸ºäº†åŠ é€Ÿä¸‹è½½ä½ å¯ä»¥ä½¿ç”¨ [hf å›½å†…é•œåƒ](https://hf-mirror.com/)ã€‚

```shell
huggingface-cli login
```

å¤åˆ¶ä¸‹é¢æ‰€æœ‰å‘½ä»¤ï¼ˆåŒ…å« '#' ç¬¦å·ï¼‰æ‰§è¡Œã€‚

```shell
# ä¸‹è½½ repo
git clone https://github.com/internlm/huixiangdou --depth=1 && cd huixiangdou

# ä¸‹è½½èŠå¤©è¯é¢˜
mkdir repodir
git clone https://github.com/open-mmlab/mmpose --depth=1 repodir/mmpose
git clone https://github.com/tpoisonooo/huixiangdou-testdata --depth=1 repodir/testdata

# å®‰è£…è§£æ word æ–‡æ¡£æ‰€éœ€ä¾èµ–
apt install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig libpulse-dev
# å®‰è£… python ä¾èµ–
pip install -r requirements.txt

# æŠŠ repodir çš„ç‰¹å¾ä¿å­˜åˆ° workdir
mkdir workdir
python3 -m huixiangdou.service.feature_store
```

é¦–æ¬¡è¿è¡Œå°†è‡ªåŠ¨ä¸‹è½½é…ç½®ä¸­çš„ [text2vec æ¨¡å‹](./config.ini)ã€‚è€ƒè™‘åˆ° huggingface è¿æ¥é—®é¢˜ï¼Œå»ºè®®å…ˆæ‰‹åŠ¨ä¸‹è½½åˆ°æœ¬åœ°ï¼Œç„¶ååœ¨ `config.ini` è®¾ç½®æ¨¡å‹è·¯å¾„ã€‚ä¾‹å¦‚ï¼š

```shell
# config.ini
[feature_store]
..
model_path = "/path/to/text2vec-model"

# .github/scripts/config-ci.ini æ˜¯ä¸€ä¸ªä¿®æ”¹å¥½çš„ç¤ºä¾‹ï¼Œç”¨äºæœ¬é¡¹ç›®çš„ CI
```

è¿è¡Œç»“æŸåï¼ŒèŒ´é¦™è±†èƒ½å¤ŸåŒºåˆ†åº”è¯¥å¤„ç†å“ªäº›ç”¨æˆ·è¯é¢˜ï¼Œå“ªäº›é—²èŠåº”è¯¥æ‹’ç»ã€‚è¯·ç¼–è¾‘ [good_questions](./resource/good_questions.json) å’Œ [bad_questions](./resource/bad_questions.json)ï¼Œå°è¯•è‡ªå·±çš„é¢†åŸŸçŸ¥è¯†ï¼ˆåŒ»ç–—ï¼Œé‡‘èï¼Œç”µåŠ›ç­‰ï¼‰ã€‚

```shell
The optimal threshold is: 0.5447442409012104, saved it..
# æ‹’ç»é—²èŠ
reject query: æœ‰å•¥ä¸­æ–‡çš„ text to speech æ¨¡å‹å—?
reject query: ä»Šå¤©ä¸­åˆåƒä»€ä¹ˆ
# æ¥å—åº•åº“è¯é¢˜
process query: mmpose å¦‚ä½•å®‰è£…ï¼Ÿ
process query: ä½¿ç”¨ç§‘ç ”ä»ªå™¨éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ
```

## STEP2. è¿è¡ŒåŸºç¡€ç‰ˆæŠ€æœ¯åŠ©æ‰‹

**é…ç½®å…è´¹ TOKEN**

èŒ´é¦™è±†ä½¿ç”¨äº†æœç´¢å¼•æ“ï¼Œç‚¹å‡» [Serper å®˜ç½‘](https://serper.dev/api-key)è·å–é™é¢ TOKENï¼Œå¡«å…¥ `config.ini`

```shell
# config.ini
..
[web_search]
x_api_key = "${YOUR-X-API-KEY}"
..
```

**æµ‹è¯•é—®ç­”æ•ˆæœ**

\[ä»…ä½“éªŒç‰ˆéœ€è¦è¿™æ­¥\] å¦‚æœä½ çš„æœºå™¨æ˜¾å­˜ä¸è¶³ä»¥æœ¬åœ°è¿è¡Œ 7B LLMï¼ˆä½äº 15Gï¼‰ï¼Œå¯å¼€å¯ `kimi` æˆ– `deepseek` [ç™½å«– 3kw é™å… token](https://platform.deepseek.com/)ã€‚å‚ç…§ [config-experience.ini](./config-experience.ini)

```ini
# config.ini
[llm]
enable_local = 0
enable_remote = 1
..
[llm.server]
..
remote_type = "deepseek"
remote_api_key = "YOUR-API-KEY"
remote_llm_max_text_length = 16000
remote_llm_model = "deepseek-chat"
```

é»˜è®¤é…ç½®ä¸­ `enable_local=1`ï¼Œé¦–æ¬¡è¿è¡Œå°†æ ¹æ®æ˜¾å­˜å¤§å°ï¼Œè‡ªåŠ¨ä¸‹è½½ä¸åŒçš„ LLMï¼Œè¯·ä¿è¯ç½‘ç»œç•…é€šã€‚å»ºè®®å…ˆæ‰‹åŠ¨ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå†ä¿®æ”¹ `config.ini` ä¸­æ¨¡å‹è·¯å¾„ã€‚

- **é docker ç”¨æˆ·**ã€‚å¦‚æœä½ **ä¸**ä½¿ç”¨ docker ç¯å¢ƒï¼Œå¯ä»¥ä¸€æ¬¡å¯åŠ¨æ‰€æœ‰æœåŠ¡ã€‚

  ```shell
  # standalone
  python3 -m huixiangdou.main --standalone
  ..
  ErrorCode.SUCCESS,
  Query: è¯·é—®å¦‚ä½•å®‰è£… mmpose ?
  Reply:
  è¦å®‰è£… mmposeï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
  1. **å‡†å¤‡ç¯å¢ƒ**ï¼š
  - å®‰è£… Minicondaã€‚
  - åˆ›å»ºå¹¶æ¿€æ´»ä¸€ä¸ªåä¸º openmmlab çš„ conda ç¯å¢ƒã€‚
  ..
  ```

  æ³¨ï¼šå¦‚æœä½¿ç”¨ deepseek è¿›è¡Œ remote llm è°ƒç”¨ï¼Œå‡ºç° 400 é”™è¯¯å¯èƒ½æ˜¯å› ä¸ºå®‰å…¨å®¡æŸ¥ï¼›åœ¨ [huixiangdou/main.py](huixiangdou/main.py) ä¸­ä¿®æ”¹ `queries = ['è¯·é—®å¦‚ä½•å®‰è£… mmpose ?']` ä¸ºå…¶ä»–é—®é¢˜å³å¯æ­£å¸¸è¿è¡Œã€‚

- **docker ç”¨æˆ·**ã€‚å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ dockerï¼Œ`HuixiangDou` çš„ Hybrid LLM Service éœ€è¦åˆ†ç¦»éƒ¨ç½²ã€‚

  ```shell
  # é¦–å…ˆå¯åŠ¨ LLM æœåŠ¡ï¼Œç›‘å¬ 8888 ç«¯å£
  python3 -m huixiangdou.service.llm_server_hybrid
  ..
  ======== Running on http://0.0.0.0:8888 ========
  (Press CTRL+C to quit)
  ```

  ç„¶åè¿è¡Œæ–°å®¹å™¨ï¼ŒæŠŠå®¿ä¸»æœºçš„ IP (æ³¨æ„ä¸æ˜¯ docker å®¹å™¨å†…çš„ IP) é…ç½®è¿› `config.ini`ï¼Œè¿è¡Œ

  ```shell
  # config.ini
  [llm]
  ..
  client_url = "http://10.140.24.142:9999/inference" # ä¸¾ä¾‹ï¼Œè¿™é‡Œéœ€è¦ä½ æ¢æˆå®¿ä¸»æœº IP

  # æ‰§è¡Œ main
  python3 -m huixiangdou.main
  ..
  ErrorCode.SUCCESS,
  Query: è¯·é—®å¦‚ä½•å®‰è£… mmpose..
  ```

## STEP3.é›†æˆé£ä¹¦/ä¸ªäººå¾®ä¿¡\[å¯é€‰\]

ç‚¹å‡»[åˆ›å»ºé£ä¹¦è‡ªå®šä¹‰æœºå™¨äºº](https://open.feishu.cn/document/client-docs/bot-v3/add-custom-bot)ï¼Œè·å–å›è°ƒ WEBHOOK_URLï¼Œå¡«å†™åˆ° config.ini

```ini
# config.ini
..
[frontend]
type = "lark"
webhook_url = "${YOUR-LARK-WEBHOOK-URL}"
```

è¿è¡Œã€‚ç»“æŸåï¼ŒæŠ€æœ¯åŠ©æ‰‹çš„ç­”å¤å°†å‘é€åˆ°é£ä¹¦ç¾¤ã€‚

```shell
python3 -m huixiangdou.main --standalone # é docker ç”¨æˆ·
python3 -m huixiangdou.main # docker ç”¨æˆ·
```

<img src="./resource/figures/lark-example.png" width="400">

- [è¿è¡Œå®Œæ•´çš„é£ä¹¦ç¾¤ç»„æ”¶å‘ã€æ’¤å›åŠŸèƒ½](./docs/add_lark_group_zh.md)
- [ä¸ªäººå¾®ä¿¡æ¥å…¥ç¤ºä¾‹](./docs/add_wechat_group_zh.md)
- è¿˜å¯ä»¥å‚è€ƒ[é’‰é’‰å¼€æ”¾å¹³å°-è‡ªå®šä¹‰æœºå™¨äººæ¥å…¥](https://open.dingtalk.com/document/robots/custom-robot-access)

## STEP4.é«˜çº§ç‰ˆ\[å¯é€‰\]

åŸºç¡€ç‰ˆå¯èƒ½æ•ˆæœä¸ä½³ï¼Œå¯å¼€å¯ä»¥ä¸‹ç‰¹æ€§æ¥æå‡æ•ˆæœã€‚é…ç½®æ¨¡æ¿è¯·å‚ç…§ [config-advanced.ini](./config-advanced.ini)

1. ä½¿ç”¨æ›´é«˜ç²¾åº¦ local LLM

   æŠŠ config.ini ä¸­çš„`llm.local` æ¨¡å‹è°ƒæ•´ä¸º `internlm2-chat-20b`ã€‚
   æ­¤é€‰é¡¹æ•ˆæœæ˜¾è‘—ï¼Œä½†éœ€è¦æ›´å¤§çš„ GPU æ˜¾å­˜ã€‚

2. Hybrid LLM Service

   å¯¹äºæ”¯æŒ [openai](https://pypi.org/project/openai/) æ¥å£çš„ LLM æœåŠ¡ï¼ŒèŒ´é¦™è±†å¯ä»¥å‘æŒ¥å®ƒçš„ Long Context èƒ½åŠ›ã€‚
   ä»¥ [kimi](https://platform.moonshot.cn/) ä¸ºä¾‹ï¼Œä»¥ä¸‹æ˜¯ `config.ini` é…ç½®ç¤ºä¾‹ï¼š

   ```ini
   # config.ini
   [llm]
   enable_local = 1
   enable_remote = 1
   ..
   [llm.server]
   ..
   # open https://platform.moonshot.cn/
   remote_type = "kimi"
   remote_api_key = "YOUR-KIMI-API-KEY"
   remote_llm_max_text_length = 128000
   remote_llm_model = "moonshot-v1-128k"
   ```

   æˆ‘ä»¬åŒæ ·æ”¯æŒ chatgpt APIã€‚æ³¨æ„æ­¤ç‰¹æ€§ä¼šå¢åŠ å“åº”è€—æ—¶å’Œè¿è¡Œæˆæœ¬ã€‚

3. repo æœç´¢å¢å¼º

   æ­¤ç‰¹æ€§é€‚åˆå¤„ç†ç–‘éš¾é—®é¢˜ï¼Œéœ€è¦åŸºç¡€å¼€å‘èƒ½åŠ›è°ƒæ•´ promptã€‚

   - ç‚¹å‡» [sourcegraph-account-access](https://sourcegraph.com/users/tpoisonooo/settings/tokens) è·å– token

     ```shell
     # open https://github.com/sourcegraph/src-cli#installation
     sudo curl -L https://sourcegraph.com/.api/src-cli/src_linux_amd64 -o /usr/local/bin/src && chmod +x /usr/local/bin/src

     # å¼€å¯ sg æœç´¢ï¼Œå¹¶ä¸”æŠŠ token å¡«å…¥ config.ini
     [worker]
     enable_sg_search = 1 # first enable sg search
     ..
     [sg_search]
     ..
     src_access_token = "${YOUR_ACCESS_TOKEN}"
     ```

   - ç¼–è¾‘ repo çš„åå­—å’Œç®€ä»‹ï¼Œæˆ‘ä»¬ä»¥ opencompass ä¸ºä¾‹

     ```ini
     # config.ini
     # add your repo here, we just take opencompass and lmdeploy as example
     [sg_search.opencompass]
     github_repo_id = "open-compass/opencompass"
     introduction = "ç”¨äºè¯„æµ‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰.."
     ```

   - ä½¿ç”¨ `python3 -m huixiangdou.service.sg_search` å•æµ‹ï¼Œè¿”å›å†…å®¹åº”åŒ…å« opencompass æºç å’Œæ–‡æ¡£

     ```shell
     python3 -m huixiangdou.service.sg_search
     ..
     "filepath": "opencompass/datasets/longbench/longbench_trivia_qa.py",
     "content": "from datasets import Dataset..
     ```

   è¿è¡Œ `main.py`ï¼ŒèŒ´é¦™è±†å°†åœ¨åˆé€‚çš„æ—¶æœºï¼Œå¯ç”¨æœç´¢å¢å¼ºã€‚

4. è°ƒå‚

   é’ˆå¯¹ä¸šåŠ¡åœºæ™¯è°ƒå‚å¾€å¾€ä¸å¯é¿å…ã€‚

   - å‚ç…§ [data.json](./tests/data.json) å¢åŠ çœŸå®æ•°æ®ï¼Œè¿è¡Œ [test_intention_prompt.py](./tests/test_intention_prompt.py) å¾—åˆ°åˆé€‚çš„ prompt å’Œé˜ˆå€¼ï¼Œæ›´æ–°è¿› [worker](./huixiangdou/service/worker.py)
   - æ ¹æ®æ¨¡å‹æ”¯æŒçš„æœ€å¤§é•¿åº¦ï¼Œè°ƒæ•´[æœç´¢ç»“æœä¸ªæ•°](./huixiangdou/service/worker.py)
   - æŒ‰ç…§åœºæ™¯åå¥½ï¼Œä¿®æ”¹ config.ini ä¸­çš„ `web_search.domain_partial_order`ï¼Œå³æœç´¢ç»“æœååº

# ğŸ› ï¸ FAQ

1. æœºå™¨äººå¤ªé«˜å†·/å¤ªå˜´ç¢æ€ä¹ˆåŠï¼Ÿ

   - æŠŠçœŸå®åœºæ™¯ä¸­ï¼Œåº”è¯¥å›ç­”çš„é—®é¢˜å¡«å…¥`resource/good_questions.json`ï¼Œåº”è¯¥æ‹’ç»çš„å¡«å…¥`resource/bad_questions.json`
   - è°ƒæ•´ `repodir` ä¸­çš„æ–‡æ¡£ï¼Œç¡®ä¿ä¸åŒ…å«åœºæ™¯æ— å…³å†…å®¹

   é‡æ–°æ‰§è¡Œ `feature_store` æ¥æ›´æ–°é˜ˆå€¼å’Œç‰¹å¾åº“

2. å¯åŠ¨æ­£å¸¸ï¼Œä½†è¿è¡ŒæœŸé—´æ˜¾å­˜ OOM æ€ä¹ˆåŠï¼Ÿ

   åŸºäº transformers ç»“æ„çš„ LLM é•¿æ–‡æœ¬éœ€è¦æ›´å¤šæ˜¾å­˜ï¼Œæ­¤æ—¶éœ€è¦å¯¹æ¨¡å‹åš kv cache é‡åŒ–ï¼Œå¦‚ [lmdeploy é‡åŒ–è¯´æ˜](https://github.com/InternLM/lmdeploy/blob/main/docs/zh_cn/quantization/kv_int8.md)ã€‚ç„¶åä½¿ç”¨ docker ç‹¬ç«‹éƒ¨ç½² Hybrid LLM Serviceã€‚

3. å¦‚ä½•æ¥å…¥å…¶ä»– local LLM / æ¥å…¥åæ•ˆæœä¸ç†æƒ³æ€ä¹ˆåŠï¼Ÿ

   - æ‰“å¼€ [hybrid llm service](./huixiangdou/service/llm_server_hybrid.py)ï¼Œå¢åŠ æ–°çš„ LLM æ¨ç†å®ç°
   - å‚ç…§ [test_intention_prompt å’Œæµ‹è¯•æ•°æ®](./tests/test_intention_prompt.py)ï¼Œé’ˆå¯¹æ–°æ¨¡å‹è°ƒæ•´ prompt å’Œé˜ˆå€¼ï¼Œæ›´æ–°åˆ° [worker.py](./huixiangdou/service/worker.py)

4. å“åº”å¤ªæ…¢/ç½‘ç»œè¯·æ±‚æ€»æ˜¯å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

   - å‚è€ƒ [hybrid llm service](./huixiangdou/service/llm_server_hybrid.py) å¢åŠ æŒ‡æ•°é€€é¿é‡ä¼ 
   - local LLM æ›¿æ¢ä¸º [lmdeploy](https://github.com/internlm/lmdeploy) ç­‰æ¨ç†æ¡†æ¶ï¼Œè€ŒéåŸç”Ÿçš„ huggingface/transformers

5. æœºå™¨é…ç½®ä½ï¼ŒGPU æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

   æ­¤æ—¶æ— æ³•è¿è¡Œ local LLMï¼Œåªèƒ½ç”¨ remote LLM é…åˆ text2vec æ‰§è¡Œ pipelineã€‚è¯·ç¡®ä¿ `config.ini` åªä½¿ç”¨ remote LLMï¼Œå…³é—­ local LLM

# ğŸ€ è‡´è°¢

- [kimi-chat](https://kimi.moonshot.cn/): é•¿æ–‡æœ¬ LLMï¼Œæ”¯æŒç›´æ¥ä¸Šä¼ æ–‡ä»¶
- [BCEmbedding](https://github.com/netease-youdao/BCEmbedding): ä¸­è‹±åŒè¯­ç‰¹å¾æ¨¡å‹
- [Langchain-ChatChat](https://github.com/chatchat-space/Langchain-Chatchat): Langchain å’Œ ChatGLM çš„åº”ç”¨
- [GrabRedEnvelope](https://github.com/xbdcc/GrabRedEnvelope): å¾®ä¿¡æŠ¢çº¢åŒ…

# ğŸ“ å¼•ç”¨

```shell
@misc{kong2024huixiangdou,
      title={HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical Assistance},
      author={Huanjun Kong and Songyang Zhang and Kai Chen},
      year={2024},
      eprint={2401.08772},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
